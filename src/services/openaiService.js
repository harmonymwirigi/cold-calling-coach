// src/services/openaiService.js - FIXED VERSION WITH PROPER INTEGRATION
import OpenAI from 'openai';
import logger from '../utils/logger';

// Objection libraries for dynamic responses
const EARLY_OBJECTIONS = [
  "What's this about?",
  "I'm not interested",
  "We don't take cold calls",
  "Now is not a good time",
  "I have a meeting",
  "Can you call me later?",
  "Send me an email",
  "Who gave you this number?",
  "What are you trying to sell me?",
  "Is this a sales call?"
];

const IMPATIENCE_PHRASES = [
  "Hello? Are you still with me?",
  "Can you hear me?",
  "Still on the line?",
  "I don't have much time for this."
];

export class OpenAIService {
  constructor() {
    this.conversationHistory = [];
    this.currentStage = 'greeting';
    this.usedObjections = new Set();
    this.sessionData = {};
    this.isInitialized = false;
    this.client = null;
    this.useMockMode = false;
  }

  async initialize() {
    try {
      if (this.isInitialized) return true;

      logger.log('ü§ñ Initializing OpenAI service...');

      if (!process.env.REACT_APP_OPENAI_API_KEY) {
        logger.warn('‚ö†Ô∏è OpenAI API key not found - using fallback responses');
        this.useMockMode = true;
      } else {
        this.client = new OpenAI({
          apiKey: process.env.REACT_APP_OPENAI_API_KEY,
          dangerouslyAllowBrowser: true
        });
        this.useMockMode = false;
      }

      this.isInitialized = true;
      logger.log('‚úÖ OpenAI service initialized');
      return true;

    } catch (error) {
      logger.error('‚ùå OpenAI service initialization failed:', error);
      this.useMockMode = true;
      this.isInitialized = true;
      return true;
    }
  }

  // CRITICAL FIX: Main method to get AI prospect response
  async getProspectResponse(userInput, context, stage = 'greeting') {
    try {
      logger.log('ü§ñ AI Processing:', { userInput: userInput.substring(0, 50), stage, context: context.roleplayType });
      
      this.currentStage = stage;
      
      // Handle silence
      if (!userInput || userInput.trim() === '') {
        return {
          success: true,
          response: this.getImpatiencePhrase(),
          stage,
          nextStage: stage,
          shouldHangUp: false
        };
      }

      // CRITICAL FIX: Always try real AI first, then fallback
      let aiResponse = null;
      let shouldUseFallback = this.useMockMode;

      if (!shouldUseFallback) {
        try {
          aiResponse = await this.callOpenAIAPI(userInput, context, stage);
        } catch (error) {
          logger.warn('OpenAI API failed, using fallback:', error);
          shouldUseFallback = true;
        }
      }

      if (shouldUseFallback || !aiResponse) {
        aiResponse = this.generateFallbackResponse(userInput, context, stage);
      }

      // Parse response and determine next action
      const { nextStage, shouldHangUp } = this.determineNextAction(
        userInput, 
        aiResponse, 
        stage, 
        context
      );

      // Add to conversation history
      this.conversationHistory.push(
        { role: 'user', content: userInput },
        { role: 'assistant', content: aiResponse }
      );

      return {
        success: true,
        response: aiResponse,
        evaluation: { passed: true, feedback: 'Good response!' },
        stage,
        nextStage,
        shouldHangUp,
        objectionUsed: this.sessionData.lastObjection
      };

    } catch (error) {
      logger.error('‚ùå OpenAI API error:', error);
      
      // Always provide fallback
      const fallbackResponse = this.generateFallbackResponse(userInput, context, stage);
      
      return {
        success: true,
        response: fallbackResponse,
        evaluation: { passed: true, feedback: 'Keep practicing!' },
        stage,
        nextStage: this.getNextStage(stage),
        shouldHangUp: false
      };
    }
  }

  // CRITICAL FIX: Proper OpenAI API integration
  async callOpenAIAPI(userInput, context, stage) {
    if (!this.client) {
      throw new Error('OpenAI client not initialized');
    }

    const messages = this.buildGPTPrompt(userInput, context, stage);
    
    logger.log('üì° Calling OpenAI API with messages:', messages.length);

    const response = await this.client.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: messages,
      max_tokens: 150,
      temperature: 0.7,
      presence_penalty: 0.6,
      frequency_penalty: 0.3
    });

    if (!response.choices || !response.choices[0] || !response.choices[0].message) {
      throw new Error('Invalid OpenAI response structure');
    }

    const aiResponse = response.choices[0].message.content.trim();
    logger.log('‚úÖ OpenAI API response received:', aiResponse.substring(0, 50));
    
    return aiResponse;
  }

  // CRITICAL FIX: Build proper GPT prompt for roleplay
  buildGPTPrompt(userInput, context, stage) {
    const character = this.getCurrentCharacter(context);
    const systemPrompt = this.buildSystemPrompt(character, context, stage);
    
    const messages = [
      {
        role: "system",
        content: systemPrompt
      }
    ];

    // Add conversation history (last 4 exchanges to maintain context)
    const recentHistory = this.conversationHistory.slice(-8);
    messages.push(...recentHistory);

    // Add current user input
    messages.push({
      role: "user",
      content: userInput
    });

    return messages;
  }

  // CRITICAL FIX: Build character-specific system prompt
  buildSystemPrompt(character, context, stage) {
    const basePrompt = `You are ${character.name}, ${character.title} at ${character.company}.`;
    
    let roleplayPrompt = '';
    
    switch (context.roleplayType) {
      case 'opener_practice':
        roleplayPrompt = this.buildOpenerPrompt(character, stage);
        break;
      case 'pitch_practice':
        roleplayPrompt = this.buildPitchPrompt(character, stage);
        break;
      case 'full_simulation':
        roleplayPrompt = this.buildFullCallPrompt(character, stage);
        break;
      default:
        roleplayPrompt = this.buildGeneralPrompt(character, stage);
    }

    return `${basePrompt}\n\n${roleplayPrompt}\n\nKeep responses under 30 words and sound natural.`;
  }

  buildOpenerPrompt(character, stage) {
    if (stage === 'greeting') {
      return `You just answered a cold call. Respond with a simple greeting like "Hello?" or "${character.name} speaking." Then wait for their opener.`;
    } else if (stage === 'opener') {
      // Give an objection after they deliver their opener
      const objection = this.getRandomObjection('early');
      return `The caller just gave their opener. Respond with this objection: "${objection}"`;
    } else if (stage === 'objection') {
      return `The caller is handling your objection. If they show empathy and ask questions, become more receptive. If they argue, be resistant.`;
    }
    
    return `Continue the cold call conversation naturally as a busy professional.`;
  }

  buildPitchPrompt(character, stage) {
    return `You're listening to a sales pitch. Act like a skeptical but fair business professional. Ask relevant questions and give appropriate objections.`;
  }

  buildFullCallPrompt(character, stage) {
    return `You're receiving a complete cold call. Act naturally as a business professional - sometimes interested, sometimes skeptical, but always realistic.`;
  }

  buildGeneralPrompt(character, stage) {
    return `Act as a realistic business professional receiving a cold call. Be appropriately challenging but fair.`;
  }

  // Get current character from context
  getCurrentCharacter(context) {
    // Default character if none provided
    return context.character || {
      name: 'Sarah Mitchell',
      title: 'VP of Marketing',
      company: 'TechCorp Solutions'
    };
  }

  // Determine next action based on conversation flow
  determineNextAction(userInput, aiResponse, stage, context) {
    let nextStage = stage;
    let shouldHangUp = false;

    switch (context.roleplayType) {
      case 'opener_practice':
        ({ nextStage, shouldHangUp } = this.handleOpenerFlow(userInput, aiResponse, stage));
        break;
      case 'pitch_practice':
        ({ nextStage, shouldHangUp } = this.handlePitchFlow(userInput, aiResponse, stage));
        break;
      default:
        nextStage = this.getNextStage(stage);
        shouldHangUp = false;
    }

    return { nextStage, shouldHangUp };
  }

  handleOpenerFlow(userInput, aiResponse, stage) {
    switch (stage) {
      case 'greeting':
        return { nextStage: 'opener', shouldHangUp: false };
      case 'opener':
        // Random hangup chance (20%)
        if (Math.random() < 0.2) {
          return { nextStage: 'hangup', shouldHangUp: true };
        }
        return { nextStage: 'objection', shouldHangUp: false };
      case 'objection':
        // Check if they handled objection well
        const handledWell = this.evaluateObjectionHandling(userInput);
        if (handledWell) {
          return { nextStage: 'mini_pitch', shouldHangUp: false };
        } else {
          return { nextStage: 'hangup', shouldHangUp: true };
        }
      case 'mini_pitch':
        return { nextStage: 'hangup', shouldHangUp: true };
      default:
        return { nextStage: stage, shouldHangUp: false };
    }
  }

  handlePitchFlow(userInput, aiResponse, stage) {
    // Simpler flow for pitch practice
    return { nextStage: this.getNextStage(stage), shouldHangUp: false };
  }

  // Simple objection handling evaluation
  evaluateObjectionHandling(userInput) {
    const lowerInput = userInput.toLowerCase();
    
    // Check for empathy words
    const hasEmpathy = lowerInput.includes('understand') || 
                      lowerInput.includes('appreciate') || 
                      lowerInput.includes('respect') ||
                      lowerInput.includes('realize');
    
    // Check they didn't argue
    const isArgumentative = lowerInput.includes('but ') || 
                           lowerInput.includes('however') || 
                           lowerInput.includes('actually');
    
    // Check for question at the end
    const hasQuestion = userInput.trim().endsWith('?');
    
    return hasEmpathy && !isArgumentative && hasQuestion;
  }

  // Get next stage in conversation flow
  getNextStage(currentStage) {
    const stageFlow = {
      greeting: 'opener',
      opener: 'objection',
      objection: 'mini_pitch',
      mini_pitch: 'post_pitch',
      post_pitch: 'meeting',
      meeting: 'hangup'
    };
    
    return stageFlow[currentStage] || 'hangup';
  }

  // CRITICAL FIX: Improved fallback response system
  generateFallbackResponse(userInput, context, stage) {
    logger.log('üîÑ Using fallback response for stage:', stage);

    switch (context.roleplayType) {
      case 'opener_practice':
        return this.generateOpenerFallback(userInput, stage);
      case 'pitch_practice':
        return this.generatePitchFallback(userInput, stage);
      default:
        return this.generateGeneralFallback(userInput, stage);
    }
  }

  generateOpenerFallback(userInput, stage) {
    switch (stage) {
      case 'greeting':
        return "Hello, who is this?";
      case 'opener':
        const objection = this.getRandomObjection('early');
        return objection;
      case 'objection':
        const lowerInput = userInput.toLowerCase();
        if (lowerInput.includes('understand') || lowerInput.includes('appreciate')) {
          return "Okay, what exactly are you offering?";
        } else {
          return "I really don't have time for this.";
        }
      case 'mini_pitch':
        return "That sounds interesting. Let me think about it.";
      default:
        return "Can you tell me more?";
    }
  }

  generatePitchFallback(userInput, stage) {
    const pitchResponses = [
      "Tell me more about that.",
      "How exactly does that work?",
      "What makes you different?",
      "That's expensive. Is it worth it?",
      "We already have a solution for that.",
      "I'd need to see some proof of that."
    ];
    
    return pitchResponses[Math.floor(Math.random() * pitchResponses.length)];
  }

  generateGeneralFallback(userInput, stage) {
    const generalResponses = [
      "I see. Tell me more.",
      "How exactly would that help us?",
      "What's the cost involved?",
      "We're pretty busy right now.",
      "I'll need to think about that.",
      "Can you send me some information?"
    ];
    
    return generalResponses[Math.floor(Math.random() * generalResponses.length)];
  }

  // Get random objection from pool
  getRandomObjection(type) {
    const objections = EARLY_OBJECTIONS;
    const available = objections.filter(obj => !this.usedObjections.has(obj));
    
    if (available.length === 0) {
      this.usedObjections.clear();
    }
    
    const finalList = available.length > 0 ? available : objections;
    const selected = finalList[Math.floor(Math.random() * finalList.length)];
    this.usedObjections.add(selected);
    this.sessionData.lastObjection = selected;
    
    logger.log('üé≠ Selected objection:', selected);
    return selected;
  }

  // Get impatience phrase for silence
  getImpatiencePhrase() {
    return IMPATIENCE_PHRASES[Math.floor(Math.random() * IMPATIENCE_PHRASES.length)];
  }

  // Generate coaching feedback
  async generateCoachingFeedback(sessionData) {
    return {
      sales: "Great job! Your communication was clear and professional.",
      grammar: "Your English is excellent - keep it up!",
      vocabulary: "Good word choices throughout the call.",
      pronunciation: "Speaking clearly - well done!",
      overall: "Excellent practice session! You're improving with each call."
    };
  }

  // Reset conversation state
  resetConversation() {
    this.conversationHistory = [];
    this.currentStage = 'greeting';
    this.usedObjections.clear();
    this.sessionData = {};
    logger.log('üîÑ OpenAI conversation reset');
  }

  // Get conversation state
  getState() {
    return {
      isInitialized: this.isInitialized,
      useMockMode: this.useMockMode,
      currentStage: this.currentStage,
      conversationLength: this.conversationHistory.length
    };
  }
}

// Export singleton instance
export const openAIService = new OpenAIService();
export default openAIService;